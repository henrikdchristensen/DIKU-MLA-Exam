{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. National Forest Inventory (18 points) [Christian]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filename = 'NFI_filtered_cleaned.csv'\n",
    "filepath = os.path.join('data', filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://raw.githubusercontent.com/christian-igel/ML/main/data/NFI_filtered_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "url_data = 'https://raw.githubusercontent.com/christian-igel/ML/main/data/' + filename\n",
    "\n",
    "if not os.access(filepath, os.R_OK):\n",
    "    print('downloading', url_data)\n",
    "    try:\n",
    "        r = requests.get(url_data)\n",
    "        r.raise_for_status()\n",
    "        open(filepath, 'wb').write(r.content)\n",
    "    except Exception as e:\n",
    "        print('download failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h_mean_1_</th>\n",
       "      <th>h_mean_2_</th>\n",
       "      <th>h_std_1_</th>\n",
       "      <th>h_std_2_</th>\n",
       "      <th>h_coov_1_</th>\n",
       "      <th>h_coov_2_</th>\n",
       "      <th>h_kur_1_</th>\n",
       "      <th>h_kur_2_</th>\n",
       "      <th>h_skew_1_</th>\n",
       "      <th>h_skew_2_</th>\n",
       "      <th>...</th>\n",
       "      <th>red_q50</th>\n",
       "      <th>red_q25</th>\n",
       "      <th>blue_q75</th>\n",
       "      <th>blue_q50</th>\n",
       "      <th>blue_q25</th>\n",
       "      <th>green_q75</th>\n",
       "      <th>green_q50</th>\n",
       "      <th>green_q25</th>\n",
       "      <th>BMag_ha</th>\n",
       "      <th>C_frac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.409585</td>\n",
       "      <td>10.662752</td>\n",
       "      <td>5.105565</td>\n",
       "      <td>3.577681</td>\n",
       "      <td>1.051682</td>\n",
       "      <td>0.368356</td>\n",
       "      <td>1.838990</td>\n",
       "      <td>0.649883</td>\n",
       "      <td>0.288754</td>\n",
       "      <td>-0.315015</td>\n",
       "      <td>...</td>\n",
       "      <td>22139.944233</td>\n",
       "      <td>18636.451204</td>\n",
       "      <td>22296.699620</td>\n",
       "      <td>19473.237009</td>\n",
       "      <td>16995.629911</td>\n",
       "      <td>25513.125475</td>\n",
       "      <td>21920.365019</td>\n",
       "      <td>18655.026616</td>\n",
       "      <td>113.640865</td>\n",
       "      <td>0.468314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.411430</td>\n",
       "      <td>5.781779</td>\n",
       "      <td>2.692018</td>\n",
       "      <td>1.783427</td>\n",
       "      <td>0.852839</td>\n",
       "      <td>0.140408</td>\n",
       "      <td>17.111033</td>\n",
       "      <td>4.515893</td>\n",
       "      <td>1.561340</td>\n",
       "      <td>0.909943</td>\n",
       "      <td>...</td>\n",
       "      <td>8326.425086</td>\n",
       "      <td>8049.423340</td>\n",
       "      <td>7008.356714</td>\n",
       "      <td>6988.936708</td>\n",
       "      <td>6880.897220</td>\n",
       "      <td>7293.151396</td>\n",
       "      <td>7354.904510</td>\n",
       "      <td>7232.853660</td>\n",
       "      <td>104.941748</td>\n",
       "      <td>0.499074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.007347</td>\n",
       "      <td>1.117059</td>\n",
       "      <td>0.071730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.926685</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-13.816676</td>\n",
       "      <td>-3.747779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.906589</td>\n",
       "      <td>5.994878</td>\n",
       "      <td>3.073276</td>\n",
       "      <td>2.330300</td>\n",
       "      <td>0.567644</td>\n",
       "      <td>0.272190</td>\n",
       "      <td>-1.277054</td>\n",
       "      <td>-0.690741</td>\n",
       "      <td>-0.627047</td>\n",
       "      <td>-0.845669</td>\n",
       "      <td>...</td>\n",
       "      <td>16384.000000</td>\n",
       "      <td>12800.000000</td>\n",
       "      <td>17600.000000</td>\n",
       "      <td>14848.000000</td>\n",
       "      <td>12544.000000</td>\n",
       "      <td>20224.000000</td>\n",
       "      <td>16640.000000</td>\n",
       "      <td>13568.000000</td>\n",
       "      <td>28.934917</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.438852</td>\n",
       "      <td>10.085121</td>\n",
       "      <td>4.823045</td>\n",
       "      <td>3.371879</td>\n",
       "      <td>0.835525</td>\n",
       "      <td>0.352517</td>\n",
       "      <td>-0.623700</td>\n",
       "      <td>-0.122410</td>\n",
       "      <td>0.095032</td>\n",
       "      <td>-0.389580</td>\n",
       "      <td>...</td>\n",
       "      <td>22016.000000</td>\n",
       "      <td>18432.000000</td>\n",
       "      <td>22016.000000</td>\n",
       "      <td>19200.000000</td>\n",
       "      <td>16640.000000</td>\n",
       "      <td>25344.000000</td>\n",
       "      <td>21760.000000</td>\n",
       "      <td>18688.000000</td>\n",
       "      <td>86.230206</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.894731</td>\n",
       "      <td>14.578052</td>\n",
       "      <td>6.953171</td>\n",
       "      <td>4.658597</td>\n",
       "      <td>1.272893</td>\n",
       "      <td>0.435651</td>\n",
       "      <td>1.014367</td>\n",
       "      <td>0.883007</td>\n",
       "      <td>0.947310</td>\n",
       "      <td>0.161931</td>\n",
       "      <td>...</td>\n",
       "      <td>28160.000000</td>\n",
       "      <td>24320.000000</td>\n",
       "      <td>26368.000000</td>\n",
       "      <td>23552.000000</td>\n",
       "      <td>20992.000000</td>\n",
       "      <td>30272.000000</td>\n",
       "      <td>26880.000000</td>\n",
       "      <td>23552.000000</td>\n",
       "      <td>169.278397</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.577832</td>\n",
       "      <td>31.654262</td>\n",
       "      <td>14.545132</td>\n",
       "      <td>12.496709</td>\n",
       "      <td>13.132664</td>\n",
       "      <td>1.359926</td>\n",
       "      <td>573.404330</td>\n",
       "      <td>205.440694</td>\n",
       "      <td>18.965810</td>\n",
       "      <td>7.757708</td>\n",
       "      <td>...</td>\n",
       "      <td>51200.000000</td>\n",
       "      <td>51200.000000</td>\n",
       "      <td>53376.000000</td>\n",
       "      <td>50176.000000</td>\n",
       "      <td>50176.000000</td>\n",
       "      <td>53376.000000</td>\n",
       "      <td>47104.000000</td>\n",
       "      <td>44288.000000</td>\n",
       "      <td>956.210950</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         h_mean_1_    h_mean_2_     h_std_1_     h_std_2_    h_coov_1_  \\\n",
       "count  3156.000000  3156.000000  3156.000000  3156.000000  3156.000000   \n",
       "mean      7.409585    10.662752     5.105565     3.577681     1.051682   \n",
       "std       5.411430     5.781779     2.692018     1.783427     0.852839   \n",
       "min       0.007347     1.117059     0.071730     0.000000     0.075114   \n",
       "25%       2.906589     5.994878     3.073276     2.330300     0.567644   \n",
       "50%       6.438852    10.085121     4.823045     3.371879     0.835525   \n",
       "75%      10.894731    14.578052     6.953171     4.658597     1.272893   \n",
       "max      31.577832    31.654262    14.545132    12.496709    13.132664   \n",
       "\n",
       "         h_coov_2_     h_kur_1_     h_kur_2_    h_skew_1_    h_skew_2_  ...  \\\n",
       "count  3156.000000  3156.000000  3156.000000  3156.000000  3156.000000  ...   \n",
       "mean      0.368356     1.838990     0.649883     0.288754    -0.315015  ...   \n",
       "std       0.140408    17.111033     4.515893     1.561340     0.909943  ...   \n",
       "min       0.000000    -1.926685    -3.000000   -13.816676    -3.747779  ...   \n",
       "25%       0.272190    -1.277054    -0.690741    -0.627047    -0.845669  ...   \n",
       "50%       0.352517    -0.623700    -0.122410     0.095032    -0.389580  ...   \n",
       "75%       0.435651     1.014367     0.883007     0.947310     0.161931  ...   \n",
       "max       1.359926   573.404330   205.440694    18.965810     7.757708  ...   \n",
       "\n",
       "            red_q50       red_q25      blue_q75      blue_q50      blue_q25  \\\n",
       "count   3156.000000   3156.000000   3156.000000   3156.000000   3156.000000   \n",
       "mean   22139.944233  18636.451204  22296.699620  19473.237009  16995.629911   \n",
       "std     8326.425086   8049.423340   7008.356714   6988.936708   6880.897220   \n",
       "min        0.000000      0.000000    256.000000      0.000000      0.000000   \n",
       "25%    16384.000000  12800.000000  17600.000000  14848.000000  12544.000000   \n",
       "50%    22016.000000  18432.000000  22016.000000  19200.000000  16640.000000   \n",
       "75%    28160.000000  24320.000000  26368.000000  23552.000000  20992.000000   \n",
       "max    51200.000000  51200.000000  53376.000000  50176.000000  50176.000000   \n",
       "\n",
       "          green_q75     green_q50     green_q25      BMag_ha       C_frac  \n",
       "count   3156.000000   3156.000000   3156.000000  3156.000000  3156.000000  \n",
       "mean   25513.125475  21920.365019  18655.026616   113.640865     0.468314  \n",
       "std     7293.151396   7354.904510   7232.853660   104.941748     0.499074  \n",
       "min      256.000000      0.000000      0.000000     0.002059     0.000000  \n",
       "25%    20224.000000  16640.000000  13568.000000    28.934917     0.000000  \n",
       "50%    25344.000000  21760.000000  18688.000000    86.230206     0.000000  \n",
       "75%    30272.000000  26880.000000  23552.000000   169.278397     1.000000  \n",
       "max    53376.000000  47104.000000  44288.000000   956.210950     1.000000  \n",
       "\n",
       "[8 rows x 43 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(filepath)\n",
    "df.to_csv(filepath, index=False)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_target = 'BMag_ha'\n",
    "classification_target = 'C_frac'\n",
    "features = ['h_mean_1_', 'h_mean_2_', 'h_std_1_', 'h_std_2_', 'h_coov_1_', 'h_coov_2_', 'h_skew_1_', 'h_skew_2_',\n",
    "            'IR_', 'h_q5_1_', 'h_q10_1_', 'h_q25_1_', 'h_q50_1_', 'h_q75_1_', 'h_q90_1_', 'h_q95_1_', 'h_q99_1_', 'h_q5_2_',\n",
    "            'h_q10_2_', 'h_q25_2_', 'h_q50_2_', 'h_q75_2_', 'h_q90_2_', 'h_q95_2_', 'h_q99_2_', 'red_q75', 'red_q50', 'red_q25',\n",
    "            'blue_q75', 'blue_q50', 'blue_q25', 'green_q75', 'green_q50', 'green_q25']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine training- and validation set into a single data frame, for tasks that don't require a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define set with train and validation data\n",
    "df_trainval = df.query(\"split in ['train', 'val']\")\n",
    "\n",
    "# Define set with test data\n",
    "df_test = df.query(\"split == 'test'\")\n",
    "\n",
    "# Select only the features we want to use\n",
    "X_trainval = df_trainval[features]\n",
    "X_test = df_test[features]\n",
    "\n",
    "# Convert target values from dataframes to numpy arrays\n",
    "y_trainval = df_trainval[[regression_target]].values.ravel()\n",
    "y_test = df_test[[regression_target]].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression without regularization. Report the test $R^2$ score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score (training): 0.712\n",
      "R2 score (test): 0.739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Define linear regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Fit model on TrainVal data\n",
    "lr_model.fit(X_trainval, y_trainval)\n",
    "\n",
    "# Predict on TrainVal and Test data\n",
    "lr_trainval_y_pred = lr_model.predict(X_trainval)\n",
    "lr_test_y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Print R2 scores\n",
    "print(f\"R2 score (training): {r2_score(y_trainval, lr_trainval_y_pred):.3f}\")\n",
    "print(f\"R2 score (test): {r2_score(y_test, lr_test_y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random forest with 100 and 1000 trees. Use the OOB score to determine which number of trees is better. Report OOB scores of both models and the test $R^2$ score of the better solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Define parameter grid\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 1000]\n",
    "}\n",
    "\n",
    "# Define random forest model\n",
    "rf_model = RandomForestRegressor(random_state=0, oob_score=True)\n",
    "\n",
    "# Grid search\n",
    "rf_grid_search = GridSearchCV(rf_model, param_grid=rf_param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit model with grid search on TrainVal data\n",
    "rf_grid_search.fit(X_trainval, y_trainval)\n",
    "\n",
    "# Best model from grid search\n",
    "rf_best_model = rf_grid_search.best_estimator_\n",
    "\n",
    "# Predict with best model on TrainVal and Test data\n",
    "rf_best_model_trainval_y_pred = rf_best_model.predict(X_trainval)\n",
    "rf_best_model_test_y_pred = rf_best_model.predict(X_test)\n",
    "\n",
    "# Print best number of estimators\n",
    "print(f\"Best number of estimators: {rf_grid_search.best_params_['n_estimators']}\")\n",
    "# Print OOB score\n",
    "print(f\"OOB score: {rf_best_model.oob_score_}\")\n",
    "# Print R2 scores\n",
    "print(f\"R2 score (training): {r2_score(y_trainval, rf_best_model_trainval_y_pred):.3f}\")\n",
    "print(f\"R2 score (test): {r2_score(y_test, rf_best_model_test_y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-nearest-neighbor regression. Find out if normalization to zero mean and unit variance helps. Describe how you did that. Use cross-validation to determine the number of neighbors from the range {1, 3, 5, ..., 47, 49}. Describe how you determined the number of neighbors. Report training and test $R^2$ score of the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unnormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of neighbors: 33\n",
      "R2 score (training): 0.1345567872393415\n",
      "R2 score (test): 0.02687036261417819\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "# Define parameter grid\n",
    "knn_param_grid = {'n_neighbors': list(range(1, 50, 2))} # odd numbers from 1 to 50 (majority vote, no ties)\n",
    "\n",
    "# Define kNN model and grid search\n",
    "knn_grid_search = GridSearchCV(estimator=KNeighborsRegressor(), param_grid=knn_param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit model with grid search on training set\n",
    "knn_grid_search.fit(X_trainval, y_trainval)\n",
    "\n",
    "# Best model from grid search\n",
    "knn_best_unnormalized_model = knn_grid_search.best_estimator_\n",
    "\n",
    "# Predict with best model on TrainVal and Test data\n",
    "knn_best_unnormalized_model_trainval_y_pred = knn_best_unnormalized_model.predict(X_trainval)\n",
    "knn_best_unnormalized_model_test_y_pred = knn_best_unnormalized_model.predict(X_test)\n",
    "\n",
    "# Print best number of neighbors\n",
    "print(f\"Best number of neighbors: {knn_grid_search.best_params_['n_neighbors']}\")\n",
    "# Print R2 score for training set and test set\n",
    "print(f\"R2 score (training): {r2_score(y_trainval, knn_best_unnormalized_model_trainval_y_pred)}\")\n",
    "print(f\"R2 score (test): {r2_score(y_test, knn_best_unnormalized_model_test_y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of neighbors: 41\n",
      "R2 score (training): 0.705935005362279\n",
      "R2 score (test): 0.7316752547056613\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X_train and X_test are your training and test datasets\n",
    "scaler = StandardScaler()\n",
    "X_trainval_normalized = scaler.fit_transform(X_trainval)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# Define parameter grid\n",
    "knn_param_grid = {'n_neighbors': list(range(1, 50, 2))}  # {1, 3, 5, ..., 49}\n",
    "\n",
    "# Define kNN model\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "# Grid search\n",
    "knn_grid_search = GridSearchCV(estimator=knn_model, param_grid=knn_param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit model with grid search on training set\n",
    "knn_grid_search.fit(X_trainval_normalized, y_trainval)\n",
    "\n",
    "# Best model from grid search\n",
    "knn_best_normalized_model = knn_grid_search.best_estimator_\n",
    "\n",
    "# Predict with best model on test set\n",
    "knn_best_normalized_model_y_pred = knn_best_normalized_model.predict(X_test_normalized)\n",
    "\n",
    "# Print best number of neighbors\n",
    "print(f\"Best number of neighbors: {knn_grid_search.best_params_['n_neighbors']}\")\n",
    "# Print R2 score for training set and test set\n",
    "print(f\"R2 score (training): {r2_score(y_trainval, knn_best_normalized_model.predict(X_trainval_normalized))}\")\n",
    "print(f\"R2 score (test): {r2_score(y_test, knn_best_normalized_model_y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Clustering (20 points) [Sadegh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "def kmeans(data, initial_centroids):\n",
    "    centroids = np.array([data[point] for point in initial_centroids])\n",
    "    prev_centroids = np.zeros(centroids.shape)\n",
    "    clusters = {i: [] for i in range(len(centroids))}\n",
    "    iteration = 1\n",
    "    \n",
    "    # Continue until centroids converge\n",
    "    while not np.array_equal(centroids, prev_centroids):\n",
    "        print(f\"\\nIteration {iteration}:\\n{'-' * 20}\")\n",
    "        clusters = {i: [] for i in range(len(centroids))}\n",
    "\n",
    "        # Assignment step\n",
    "        table_data = []\n",
    "        for point_name, point_coords in data.items():\n",
    "            distances = np.linalg.norm(point_coords - centroids, axis=1)\n",
    "            cluster_index = np.argmin(distances)\n",
    "            clusters[cluster_index].append(point_name)\n",
    "            table_data.append([point_name] + list(distances))\n",
    "        headers = [\"Point\"] + [f\"c{i+1}\" for i in range(len(centroids))]\n",
    "        print(tabulate(table_data, headers=headers, floatfmt=\".3f\"))        \n",
    "\n",
    "        # Update step\n",
    "        prev_centroids = centroids.copy()\n",
    "        for i, point_names in clusters.items():\n",
    "            if point_names:\n",
    "                new_centroid = np.mean([data[pn] for pn in point_names], axis=0)\n",
    "                centroids[i] = new_centroid\n",
    "                print(f\"Updated cluster center, c{i+1}: from [{prev_centroids[i][0]:.3f}, \"\n",
    "                      f\"{prev_centroids[i][1]:.3f}] to [{new_centroid[0]:.3f}, {new_centroid[1]:.3f}]\")\n",
    "\n",
    "        for i, point_names in clusters.items():\n",
    "            print(f\"Cluster c{i+1}: {point_names}\")\n",
    "        \n",
    "        iteration += 1\n",
    "    \n",
    "    # Display final results\n",
    "    print(\"\\nFinal Results:\\n\" + '-' * 20)\n",
    "    for i, point_names in clusters.items():\n",
    "        print(f\"Cluster c{i+1}: {point_names}\")\n",
    "    for i, centroid in enumerate(centroids):\n",
    "        formatted_centroid = [f\"{element:.3f}\" for element in centroid]\n",
    "        print(f\"c{i+1} = [{', '.join(formatted_centroid)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data points\n",
    "data = {\n",
    "    'A': np.array([25., 0.]),\n",
    "    'B': np.array([0., 3.]),\n",
    "    'C': np.array([0., -3.]),\n",
    "    'D': np.array([-25., 1.]),\n",
    "    'E': np.array([-25., -1.]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1:\n",
      "--------------------\n",
      "Point        c1      c2      c3\n",
      "-------  ------  ------  ------\n",
      "A        25.179   0.000  50.010\n",
      "B         6.000  25.179  25.080\n",
      "C         0.000  25.179  25.318\n",
      "D        25.318  50.010   0.000\n",
      "E        25.080  50.010   2.000\n",
      "Updated cluster center, c1: from [0.000, -3.000] to [0.000, 0.000]\n",
      "Updated cluster center, c2: from [25.000, 0.000] to [25.000, 0.000]\n",
      "Updated cluster center, c3: from [-25.000, 1.000] to [-25.000, 0.000]\n",
      "Cluster c1: ['B', 'C']\n",
      "Cluster c2: ['A']\n",
      "Cluster c3: ['D', 'E']\n",
      "\n",
      "Iteration 2:\n",
      "--------------------\n",
      "Point        c1      c2      c3\n",
      "-------  ------  ------  ------\n",
      "A        25.000   0.000  50.000\n",
      "B         3.000  25.179  25.179\n",
      "C         3.000  25.179  25.179\n",
      "D        25.020  50.010   1.000\n",
      "E        25.020  50.010   1.000\n",
      "Updated cluster center, c1: from [0.000, 0.000] to [0.000, 0.000]\n",
      "Updated cluster center, c2: from [25.000, 0.000] to [25.000, 0.000]\n",
      "Updated cluster center, c3: from [-25.000, 0.000] to [-25.000, 0.000]\n",
      "Cluster c1: ['B', 'C']\n",
      "Cluster c2: ['A']\n",
      "Cluster c3: ['D', 'E']\n",
      "\n",
      "Final Results:\n",
      "--------------------\n",
      "Cluster c1: ['B', 'C']\n",
      "Cluster c2: ['A']\n",
      "Cluster c3: ['D', 'E']\n",
      "c1 = [0.000, 0.000]\n",
      "c2 = [25.000, 0.000]\n",
      "c3 = [-25.000, 0.000]\n"
     ]
    }
   ],
   "source": [
    "initial_centroids = ['C', 'A', 'D']\n",
    "kmeans(data, initial_centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1:\n",
      "--------------------\n",
      "Point        c1      c2      c3\n",
      "-------  ------  ------  ------\n",
      "A        50.010   0.000  50.010\n",
      "B        25.080  25.179  25.318\n",
      "C        25.318  25.179  25.080\n",
      "D         0.000  50.010   2.000\n",
      "E         2.000  50.010   0.000\n",
      "Updated cluster center, c1: from [-25.000, 1.000] to [-12.500, 2.000]\n",
      "Updated cluster center, c2: from [25.000, 0.000] to [25.000, 0.000]\n",
      "Updated cluster center, c3: from [-25.000, -1.000] to [-12.500, -2.000]\n",
      "Cluster c1: ['B', 'D']\n",
      "Cluster c2: ['A']\n",
      "Cluster c3: ['C', 'E']\n",
      "\n",
      "Iteration 2:\n",
      "--------------------\n",
      "Point        c1      c2      c3\n",
      "-------  ------  ------  ------\n",
      "A        37.553   0.000  37.553\n",
      "B        12.540  25.179  13.463\n",
      "C        13.463  25.179  12.540\n",
      "D        12.540  50.010  12.855\n",
      "E        12.855  50.010  12.540\n",
      "Updated cluster center, c1: from [-12.500, 2.000] to [-12.500, 2.000]\n",
      "Updated cluster center, c2: from [25.000, 0.000] to [25.000, 0.000]\n",
      "Updated cluster center, c3: from [-12.500, -2.000] to [-12.500, -2.000]\n",
      "Cluster c1: ['B', 'D']\n",
      "Cluster c2: ['A']\n",
      "Cluster c3: ['C', 'E']\n",
      "\n",
      "Final Results:\n",
      "--------------------\n",
      "Cluster c1: ['B', 'D']\n",
      "Cluster c2: ['A']\n",
      "Cluster c3: ['C', 'E']\n",
      "[-12.500, 2.000]\n",
      "[25.000, 0.000]\n",
      "[-12.500, -2.000]\n"
     ]
    }
   ],
   "source": [
    "# Initial centroids\n",
    "initial_centroids = ['D', 'A', 'E']\n",
    "kmeans(data, initial_centroids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
